{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2 ..., 97 98 99]\n",
      " [ 0  1  2 ..., 97 98 99]\n",
      " [ 0  1  2 ..., 97 98 99]\n",
      " ..., \n",
      " [ 0  1  2 ..., 97 98 99]\n",
      " [ 0  1  2 ..., 97 98 99]\n",
      " [ 0  1  2 ..., 97 98 99]]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49\n",
      " 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74\n",
      " 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99]\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# load up some dataset. Could be anything but skdata is convenient.\n",
    "#from skdata.mnist.views import OfficialVectorClassification\n",
    "#from tqdm import tqdm\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "data = np.arange(100)\n",
    "data = np.expand_dims(data, 0)\n",
    "data = np.tile(data, (100, 1))\n",
    "print(data)\n",
    "labels = np.arange(100)\n",
    "print(labels)\n",
    "\n",
    "\n",
    "# one MUST randomly shuffle data before putting it into one of these\n",
    "# formats. Without this, one cannot make use of tensorflow's great\n",
    "# out of core shuffling.\n",
    "#np.random.shuffle(trIdx)\n",
    "\n",
    "\n",
    "\n",
    "writer = tf.python_io.TFRecordWriter(\"test.tfrecords\")\n",
    "# iterate over each example\n",
    "# wrap with tqdm for a progress bar\n",
    "\n",
    "for example_idx in range(data.shape[0]):\n",
    "    features = data[example_idx, :]\n",
    "    label = int(labels[example_idx])\n",
    "\n",
    "    # construct the Example proto boject\n",
    "    example = tf.train.Example(\n",
    "        # Example contains a Features proto object\n",
    "        features=tf.train.Features(\n",
    "          # Features contains a map of string to Feature proto objects\n",
    "          feature={\n",
    "            # A Feature contains one of either a int64_list,\n",
    "            # float_list, or bytes_list\n",
    "            'label': tf.train.Feature(\n",
    "                int64_list=tf.train.Int64List(value=[label])),\n",
    "            'image': tf.train.Feature(\n",
    "                float_list=tf.train.FloatList(value=features.astype(float))),\n",
    "    }))\n",
    "    # use the proto object to serialize the example to a string\n",
    "    serialized = example.SerializeToString()\n",
    "    # write the serialized object to disk\n",
    "    writer.write(serialized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0] 98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filename = \"test.tfrecords\"\n",
    "count = 0\n",
    "for serialized_example in tf.python_io.tf_record_iterator(filename):\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(serialized_example)\n",
    "    count+=1\n",
    "    # traverse the Example format to get data\n",
    "    image = example.features.feature['image'].float_list.value\n",
    "    label = example.features.feature['label'].int64_list.value[0]\n",
    "    # do something\n",
    "print(image, label)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def read_and_decode_single_example(filename):\n",
    "    # first construct a queue containing a list of filenames.\n",
    "    # this lets a user split up there dataset in multiple files to keep\n",
    "    # size down\n",
    "    filename_queue = tf.train.string_input_producer([filename],\n",
    "                                                    num_epochs=None)\n",
    "    # Unlike the TFRecordWriter, the TFRecordReader is symbolic\n",
    "    reader = tf.TFRecordReader()\n",
    "    # One can read a single serialized example from a filename\n",
    "    # serialized_example is a Tensor of type string.\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    # The serialized example is converted back to actual values.\n",
    "    # One needs to describe the format of the objects to be returned\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            # We know the length of both fields. If not the\n",
    "            # tf.VarLenFeature could be used\n",
    "            'label': tf.FixedLenFeature([], tf.int64),\n",
    "            'image': tf.FixedLenFeature([100], tf.float32)\n",
    "        })\n",
    "    # now return the converted data\n",
    "    label = features['label']\n",
    "    image = features['image']\n",
    "    return label, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   [  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.  14.\n",
      "  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.  28.  29.\n",
      "  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.  42.  43.  44.\n",
      "  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.  56.  57.  58.  59.\n",
      "  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.  70.  71.  72.  73.  74.\n",
      "  75.  76.  77.  78.  79.  80.  81.  82.  83.  84.  85.  86.  87.  88.  89.\n",
      "  90.  91.  92.  93.  94.  95.  96.  97.  98.  99.]\n"
     ]
    }
   ],
   "source": [
    "# returns symbolic label and image\n",
    "label, image = read_and_decode_single_example(\"test.tfrecords\")\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "# Required. See below for explanation\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)\n",
    "tf.train.start_queue_runners(sess=sess)\n",
    "\n",
    "# grab examples back.\n",
    "# first example from file\n",
    "label_val_1, image_val_1 = sess.run([label, image])\n",
    "# second example from file\n",
    "label_val_2, image_val_2 = sess.run([label, image])\n",
    "\n",
    "print(label_val_1, \" \", image_val_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "# get single examples\n",
    "label, image = read_and_decode_single_example(\"test.tfrecords\")\n",
    "# groups examples into batches randomly\n",
    "images_batch, labels_batch = tf.train.shuffle_batch(\n",
    "    [image, label], batch_size=32,\n",
    "    capacity=64,\n",
    "    min_after_dequeue=8)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)\n",
    "tf.train.start_queue_runners(sess=sess)\n",
    "labels, images= sess.run([labels_batch, images_batch])\n",
    "\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
